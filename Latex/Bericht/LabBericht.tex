\documentclass[11pt, a4paper, UKenglish]{article}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
\usepackage{tabularx}
\usepackage{mathtools}
\usepackage{color}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% load packages
\usepackage{amsmath}   % for more basic mathematical symbols
\usepackage{amssymb}   % for more mathematical symbols
\usepackage{amsthm}
\usepackage{tikz-cd}
\usepackage{tikz}
\usetikzlibrary{3d,calc,intersections}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{patterns}
\usetikzlibrary{quotes,angles,positioning}
\usepackage{dsfont}
\usepackage{ stmaryrd }
\usepackage{caption}
\usepackage[final]{listings}


\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem*{remark}{Anmerkung}
\newtheorem{definition}{Definition}
\newcommand{\bK}{\mathbb{K}}
\newcommand{\bN}{\mathbb{N}}
\newcommand{\bZ}{\mathbb{Z}}
\newcommand{\bR}{\mathbb{R}}
\newcommand{\bC}{\mathbb{C}}
\newcommand{\bS}{\mathbb{S}}
\newcommand{\bA}{\mathbb{A}}
\newcommand{\bB}{\mathbb{B}}
\newcommand{\bD}{\mathbb{D}}
\newcommand{\bE}{\mathbb{E}}
\newcommand{\bT}{\mathbb{T}}
\newcommand{\bQ}{\mathbb{Q}}

\newcommand{\im}{\textrm{im}}
\newcommand{\coker}{\textrm{coker}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\renewcommand{\figurename}{Fig.}

\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}
%Linksbündig mit vorgegebener Breite
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}
%Zentriert mit vorgegebener Breite
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash}p{#1}}
%Rechtsbündig mit vorgegebener Breite

\usepackage{BA_Titelseite}

%Namen des Verfassers der Arbeit
\author{Jacobus Leander Conradi\\Vincent Reinthal}
%Datum der Abgabe der Arbeit
\date{\today}

%Name des Betreuers
% z.B.: Prof. Dr. Peter Koepke
\betreuer{supervisor: Prof.\ Dr. Rolf Klein}
%Name des Instituts an dem der Betreuer der Arbeit tätig ist.
\zweitgutachter{secondary supervisor: Dr. Elmar Langetepe}
%Titel der Bachelorarbeit
\title{Wasserstein distance for persistence diagrams}
%Do not change!
\ausarbeitungstyp{Lab Report}

\usepackage{afterpage}

\newcommand\blankpage{%
\null
\thispagestyle{empty}%
\addtocounter{page}{-1}%
\newpage}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{language=Java,
aboveskip=2mm,
belowskip=2mm,
showstringspaces=false,
columns=flexible,
basicstyle={\small\ttfamily},
numbers=none,
numberstyle=\tiny\color{gray},
keywordstyle=\color{blue},
commentstyle=\color{dkgreen},
stringstyle=\color{mauve},
breaklines=true,
breakatwhitespace=true,
tabsize=3
}


\begin{document}
    \maketitle

	\bibliographystyle{alphadin}
    \thispagestyle{plain}
    \pagenumbering{Roman}
    \addtocounter{page}{-1}
    \tableofcontents
    \addcontentsline{toc}{section}{Table of contents}
    \vfil\null
    \clearpage
    \thispagestyle{empty}\mbox{}
    \clearpage
    \pagenumbering{arabic}

    \section{The problem}\label{sec:the-problem}
    In this work we want to take a look at the comparison of different types of image data.
    For this we consider the concept of persistent homology.
    Persistent homology can best be described as the ''recognition of structure while squinting''.
    In essence, we want to reduce a complex-looking data set to basic geometric forms.
    In particular, this approach is very intuitive and close to the subconscious recognition of structures that are characteristic of humans.


    \subsection{Persistent homology}\label{subsec:persistent-homology}
    A tool well suited for the discrete analysis of rough shapes is homology.
    This is the case, since homologous or ''warped'' data produce the same or very similar homology.
    And this is precisely what we are interested in.
    In order to calculate homologies, we first need a manifold, or in the case of a computer a necessarily discrete representation, a CW complex.
    We begin by defining the CW complex, we will be working with, namely the Čech complex for a given point set.
    The Čech complex is interesting for us, since it models the ''squinting'' part.
    It can be thought of as letting balls grow around each point from some point set and looking at the resulting shape.

    \begin{definition}[Čech complex]
        Let $X\subset \bR^d$ be a finite set and $\varepsilon>0$ arbitrary but fixed.
        We construct the Čech complex $\check C_\varepsilon(X)$ as follows.
        The $0$-skeleton is simply $X$ itself.
        Any subset $\sigma\subset X$ is in the $(|\sigma|-1)$-skeleton iff the intersection $\bigcap_{x\in\sigma}B_\varepsilon(x)$ of balls with radius $\varepsilon$ around every point of $\sigma$ is non-empty.
    \end{definition}

	By the Nerve-Theorem the Čech complex $C_\varepsilon(X)$ is homotopy equivalent to the union of balls $\bigcup_{x_i\in X} B_\varepsilon(x_i)$ (see\ \cite{eat}).
	See fig.~\ref{czech} for an example of a Čech complex.\\
    Note, that for any finite $X$ there is $\mathcal{E}>0$, such that for any $\varepsilon\geq\mathcal{E}$ we have $\check C_\varepsilon(X) = \check C_\mathcal{E}(X)$.
    Call this stabilizing CW complex $C(X):=\check C_\mathcal{E}(X)$.\\
    We define a filtration $f$ on $C(X)$ via $f:C(X)\rightarrow\bR$, $\sigma\mapsto\min\{\varepsilon|\sigma\in \check C_\varepsilon(X)\}$.
    Note that this filtration is well-defined, since for every sub-cell $\sigma'\subset\sigma$ it holds, that $f(\sigma')\leq f(\sigma)$.
    Since $X$ is finite, and hence $C(X)$, $\im(f)$ must also be finite.
    Let $\im(f)=\{\varepsilon_i|0\leq i\leq N\}$.
    We now get a sequence of CW complexes \[\check C_{\varepsilon_1}(X)\hookrightarrow \check C_{\varepsilon_2}(X)\hookrightarrow \ldots \hookrightarrow \check C_{\varepsilon_{N-1}}(X)\hookrightarrow \check C_{\varepsilon_N}(X).\]
    To extract information from this sequence, we use persistent homology. Persistent homology is looking at the evolution of the generators, as they get passed from one complex in the sequence to the next.

    \begin{definition}[Persistent homology]
        Let \[X_1\xhookrightarrow{\iota_1} X_2\xhookrightarrow{\iota_2} \ldots\xhookrightarrow{\iota_{n-2}} X_{n-1}\xhookrightarrow{\iota_{n-1}} X_n\] be a sequence of CW complex embeddings.
        For every $k\geq 0$ this implies a sequence of homology groups
        \[H_k(X_1)\xrightarrow{\iota_{1}^*} H_k(X_2)\xrightarrow{\iota_{2}^*}\ldots \xrightarrow{\iota_{n-2}^*} H_k(X_{n-1})\xrightarrow{\iota_{n-1}^*} H_k(X_n).\]
        For every $0\leq i<j\leq n$ we begin with $\mathcal{L}_i^j(X)_k$ the set of generators $\sigma\in\coker(\iota_{i-1}^*)$, such that $\iota_{j-2}^*\circ\cdots\circ\iota_{i}^*(\sigma)\neq0$ but $\iota_{j-1}^*\circ\cdots\circ\iota_{i}^*(\sigma)=0$.
        Now to get the persistent homology from this, we need to apply the so called ''elder rule''.
        It may happen, that $\sigma_1\in\mathcal{L}_i^l(X)_k$ and $\sigma_2\in\mathcal{L}_j^l(X)_k$ exist (w.l.o.g. $i<j$), such that $\sigma_1$ equals $\sigma_2$ at some point $t<l$.
        In this case, we kill the ''younger'' one of the two, i.e.\ moving $\sigma_2$ to $\mathcal{L}_j^t(X)_k$, or removing completely, if $j=t$.
        We will call this reduced family $\{\mathcal{L}_i^j(X)_k|0\leq i<j\leq n,k\geq0\}$ the persistent homology of $\{X_i\}$.
    \end{definition}
    \begin{figure}
        \centering
        \begin{tikzpicture}
            \filldraw (0,0) coordinate(a) circle (3pt);
            \filldraw (-1,1) coordinate(b) circle (3pt);
            \filldraw (0.3,0.9) coordinate(c) circle (3pt);
            \filldraw (0,-1.3) coordinate(d) circle (3pt);
            \filldraw (-1,-2) coordinate(e) circle (3pt);
            \filldraw (-2,-1.5) coordinate(f) circle (3pt);
            \filldraw (-3,-0.5) coordinate(g) circle (3pt);
            \filldraw (-2,0.5) coordinate(h) circle (3pt);

            \filldraw[opacity=0.3] (a) circle (0.8);
            \filldraw[opacity=0.3] (b) circle (0.8);
            \filldraw[opacity=0.3] (c) circle (0.8);
            \filldraw[opacity=0.3] (d) circle (0.8);
            \filldraw[opacity=0.3] (e) circle (0.8);
            \filldraw[opacity=0.3] (f) circle (0.8);
            \filldraw[opacity=0.3] (g) circle (0.8);
            \filldraw[opacity=0.3] (h) circle (0.8);
            \begin{scope}[shift={(5,0)}]
            \filldraw (0,0) coordinate(a) circle (3pt);
            \filldraw (-1,1) coordinate(b) circle (3pt);
            \filldraw (0.3,0.9) coordinate(c) circle (3pt);
            \filldraw (0,-1.3) coordinate(d) circle (3pt);
            \filldraw (-1,-2) coordinate(e) circle (3pt);
            \filldraw (-2,-1.5) coordinate(f) circle (3pt);
            \filldraw (-3,-0.5) coordinate(g) circle (3pt);
            \filldraw (-2,0.5) coordinate(h) circle (3pt);

            \draw (a) -- (b);
            \draw (a) -- (c);
            \draw (c) -- (b);

            \filldraw [opacity=0.3] (a) -- (b) -- (c);

            \draw (a) -- (d);
            \draw (d) -- (e);
            \draw (e) -- (f);
            \draw (f) -- (g);
            \draw (g) -- (h);
            \draw (h) -- (b);
            \end{scope}
        \end{tikzpicture}
        \caption{\textit{A Čech complex for a given $\varepsilon$ and generating point set.}}
        \label{czech}
    \end{figure}
	In essence persistent homology stores the lives and deaths of various generators.
	If we input the sequence we got from the Čech complex into the persistent homology, we can analyse the resulting ''shape'' of the input data after ''squinting''.\\
    We want to calculate this persistent homology for the Čech complex of given sets of $2$-dimensional points efficiently and will take a look at different approaches to calculate these.
    \subsubsection{Persistence Diagrams}\label{subsec:persistence-diagrams}
    In order to work with persistent homology more intuitively we want to visualize these.
    A particular type of visualization we want to work with are persistence diagrams.
    Here we mark the point $(t_1,t_2)$ in $\bR^2$ for every generator who is born at time $t_1$ and dies at time $t_2$.
    In more general terms, for every $\sigma\in\mathcal{L}_i^j(X)_k$ mark $(\varepsilon_i,\varepsilon_j)$ in $\bR^2$.
    \begin{figure}
        \centering
        \begin{tikzpicture}
            % Achsen zeichnen
            \draw[->,thick] (0,0) -- (5,0) node[right] {$x$};
            \draw[color=blue] (0,0) -- (5,5);
            \draw[->,thick] (0,0) -- (0,5) node[above] {$y$};
            %Punkte einzeichnen:

            \filldraw[color=red] (0,0.3) coordinate(a) circle (3pt);
            \filldraw[color=red] (0,1) coordinate(a) circle (3pt);
            \filldraw[color=red] (0,1.3) coordinate(a) circle (3pt);
            \filldraw[color=red] (0,3) coordinate(a) circle (3pt);
            \filldraw[color=red] (0,4) coordinate(a) circle (3pt);
            \filldraw[color=red] (0,3.3) coordinate(a) circle (3pt);
            \filldraw[color=red] (0,2) coordinate(a) circle (3pt);
            \filldraw[color=red] (0,2.2) coordinate(a) circle (3pt);
            \filldraw[color=red] (0,2.6) coordinate(a) circle (3pt);


            \filldraw[color=green] (2,3) coordinate(a) circle (3pt);
            \filldraw[color=green] (1,1.1) coordinate(a) circle (3pt);
            \filldraw[color=green] (3,4) coordinate(a) circle (3pt);

        \end{tikzpicture}
        \caption{\textit{A persistence-diagram.
        Red dots represent the $0$th, green dots the $1$st homology}}
        \label{fig2}
    \end{figure}

	Note that the points marked in this way are always above the diagonal $\Delta=\{(x,x)\in\bR^2|x\in\bR\}$, where points directly on the diagonal represent generators that die quickly after birth, and points far from the diagonal represent generators that live very long.
    Fig.\ \ref{fig2} is an example for a persistence diagram which shows generators of the zeroth and first homology.
    One can see that the generators of the zeroth homology, which represent connected components, are all born at time $0$ and die when the connected components merge.\\
    \subsection{Wasserstein distance}\label{subsec:wasserstein-distance}

    Now let two such persistence diagrams be given.
    To define a distance of these two diagrams, we consider the Wasserstein distance often used in probability theory.
    This is defined as the ''minimum effort to move one probability distribution to another''.
    In our concrete application we define this as follows.
    \begin{definition}[Wasserstein distance]
        Let two finite point sets $X$ and $Y$ with $|X|=|Y|$ be given.
        Then the Wasserstein distance is given by\[W_p(X,Y) = \min_{\varphi:X\rightarrow Y}\left(\sum_{x\in X}||x-\varphi(x)||^p\right)^{\frac{1}{p}},\]
        where the minimum is taken over all bijections $\varphi:X\rightarrow Y$, with $||\cdot||$ being the $\ell_2$-norm in $\bR^2$.
    \end{definition}
    A special case $W_\infty(\cdot,\cdot)$ we will call the Bottleneck distance.\\
    Notice the restraint $|X| = |Y|$.
    We want to adapt this such that differently sized sets can be compared with each other as well.
    For this we want to compare different approaches qualitatively.

    \subsection{Feature points}\label{subsec:feature-proposals}

    As a final step, we will examine methods to find a representative set of points $X$ for a given image to use as input for calculating persistent homology.
    Again, we want to compare different methods and compare them in the context of persistent homology.
    \section{Persistent homology}\label{sec:persistent-homology2}

    In this chapter we want to focus on the implementation for the computation of the Čech complex, as well as the calculation of persistent homology and persistence diagrams.
    Since we limit ourselves to $2$-dimensional point sets $X$, it is sufficient to limit $C(X)$ to its $2$-skeleton, since all higher homologies vanish.


    \subsection{Computation of the Čech complex}\label{subsec:čech-complex}

    To calculate the Čech complex we first look at the Voronoi diagram for a given point set $X$ in $2$-dimensional space.
    Here $\bR^2$ is divided into regions, so that in each region there is exactly one point $x\in X$, and for every other point $y$ in this region $x$ is the nearest point of $X$ to $y$.\\
    From the Voronoi diagram we can extract the Čech complex.
    We begin by setting the $0$-skeleton to $X$ itself, and the filtration value of every vertex to $0$.
    We add a $1$-cell $[x,y]$ to the complex, whenever the Voronoi regions of $x$ and $y$ intersect in a line segment.
    The distance of $x$ and $y$ also gives us the filtration value $f([x,y]) = \frac{||x-y||}{2}$ of the edge.
    After adding all these $1$-cells, we get the planar dual-graph, the DeLauney triangulation of the points from $X$, when we interpret $1$-cells as edges of a graph.\\
    It gets more complicated with $2$-cells.
    Here we have to make an important case distinction.
    If more than two Voronoi regions intersect, then their respective vertices form a circuit in the DeLauney triangulation and a $2$-cell in the Čech complex.
    Note that in $2$ dimensions this intersections is always exactly one point.
    But what exactly is the filtration value?\\
    This is where the following case distinction comes into play.
    Looking at the convex hull of the points $x_1,\ldots x_{k-1}\in X$, whose Voronoi regions intersect in $v$, it can happen that $v$ is inside or outside the convex hull.
    If the point $v$ is inside the convex hull, the filtration value must be chosen as the distance of $v$ to some $x_i$, which is the same for all different $x_j$, since otherwise $v$ is not the intersection of these regions.
    Note that this value $f([x_1,\ldots,x_{k-1}])=||v-x_1||$ corresponds to the exact value, at which point the ''hole'' enclosed by balls of radius $||v-x_1||$ around $x_1,\ldots,x_{k-1}$ dies.\\
    \input{snippet1.tex}
    In the other case, the $k-1$ balls around $x_1,\ldots,x_{k-1}$ intersect as soon, as all $1$-cells $[x_i,x_{i+1}]$ exist, or geometrically all pairs of balls around $x_i$ and $x_{i+1}$ intersect.
    So $f([x_1,\ldots,x_{k-1}])=\max_{1\leq i<k} f(\{x_i,x_{i+1}\})$, where $x_k=x_1$ for convenience.
    We want to call these $2$-cells \textit{degenerate}.
    For the implementation in Java we decided to use a library which calculates the Voronoi diagram.
    We calculate the planar dual graph based on the output of the Voronoi Library.
    We see in fig.~\ref{fig3}, that in the case of degenerate $2$-cells we use a \texttt{EdgeFaceAction} to insert the $1$-cell with highest filtration value of the circuit and the $2$-cell in the same time step corresponding to equal filtration values.
    What exactly insertion means will be covered in Section~\ref{subsec:calculation-of-persistent-homology}.\\
    Note that calling $0$-cells vertices, $1$-cells edges and $2$-cells faces makes sense geometrically.

    \subsection{Calculation of persistent homology}\label{subsec:calculation-of-persistent-homology}

    Since the $1$-skeleton is the same as a digraph, we save the complex as a graph and keep an additional list of lists of edges given by the boundary of $2$-cells.
    And since the second (and higher) homology is always zero, due to our choice of $2$-dimensional data, this suffices.\\
    We now insert all  the $0$-, $1$- and $2$-cells one by one into the graph/list, according to their filtration values from small to big.
    These insertions we may also call actions, since later on, we will not only insert but also modify data.
    This corresponds to growing the balls around each point and looking at the resulting union.
    However only the filtration values are interesting, in the sense, that something in the structure of the union changes.\\
    To respect the ''elder rule'', we need to make a choice for $0$-cells which vertices are older than other vertices.
    Since the choice has no influence on the homology, and this on the persistence diagram, we number the vertices arbitrarily.
    We use this numbering when calculating the first homology as an orientation of the edges.\\
    The main task in our implementation is the calculation of the first homology.
    For the zeroth homology we only have to remember whenever we add an edge whether the two vertices are in the same or different connected components.
    To maintain the elder rule for these, we keep a reference to the oldest vertex in each connected component.
    If the added edge is between two different connected components, we update for one of the connected components which the new oldest vertex is, and remember that a generator of the zeroth homology has died.\\
    Generators of the first homology of $C_\varepsilon(X)$ live in the kernel of the boundary operator $\delta_1:C_1(C_\varepsilon(X))\rightarrow C_0(C_\varepsilon(X))$, where $C_1(\cdot)$ and $C_0(\cdot)$ are the $1$- and $0$-cycles of the input complex.
    The kernel of $\delta_1$ are just all circuits on the graph.
    Hence we must find all possible circuits in the graph, and then find out which circuits die via linear combinations of these, to compute the first homology.
    To find circuits, we check whenever we add an edge $e=(v,w)$ (corresponding to the $1$-cell $[v,w]$) whether $v$ and $w$ are in the same connected component.
    If this is the case, we find a $v,w$-path $P$ in $G\setminus \{e\}$.
    Then we add the circuit $P\cup \{e\}$ to the set of generators of the first homology.
    At the time this generator is added, $e$ is completely new to the graph and is not yet contained in any edge of a $2$-cell or other circuit, so the circuit $P\cup\{e\}$ is linearly independent from all other circuits and relations until at least the next insertion.\\
    If a $2$-cell is added, the circuit describing the boundary of the $2$-cell is added to the list of $2$-cells.
    Every time a $2$-cell is added, we have to check if a circuit dies.
    For this we check the kernel of the matrix:
    \[\begin{Bmatrix}
          c_{11} & c_{21} & \ldots &c_{n1} & r_{11} & \ldots  & r_{k1}\\
          c_{12} & c_{22} & \ldots &c_{n2} & r_{12} & \ldots  & r_{k2}\\
          \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
          c_{1m} & c_{2m} & \ldots &c_{nm} & r_{1m} & \ldots  & r_{km}
    \end{Bmatrix}\]
    Where $c_{ij} = \sum_{e_j\in P_i} 1 - \sum_{e_j*\in P_i}1$ and $r_{ij} = \sum_{e_j\in R_i} 1 - \sum_{e_j^*\in R_i}1$, where $P_i$ are the generator circuits and $R_i$ are the relation circuits, and $e_j$ is an edge and $e_j^*$ is the inverted edge.
    \begin{figure}
    	\centering
        \begin{tikzpicture}
            \filldraw (0,0) coordinate(a) circle (3pt);
            \filldraw (-1,1) coordinate(b) circle (3pt);
            \filldraw (0.3,0.9) coordinate(c) circle (3pt);
            \filldraw (0,-1.3) coordinate(d) circle (3pt);
            \filldraw (-1,-2) coordinate(e) circle (3pt);
            \filldraw (-2,-1.5) coordinate(f) circle (3pt);
            \filldraw (-3,-0.5) coordinate(g) circle (3pt);
            \filldraw (-2,0.5) coordinate(h) circle (3pt);

            \draw [-{Latex[length=2mm,width=2mm]},color=red] (a) -- (b) node[midway,below,sloped,color=black]{a};
            \draw [-{Latex[length=2mm,width=2mm]},color=red](a) -- (c)node[midway,below,sloped,color=black]{b};
            \draw [-{Latex[length=2mm,width=2mm]},color=red](b) -- (c)node[midway,above,sloped,color=black]{c};

            \filldraw [opacity=0.3] (a) -- (b) -- (c);

            \draw[-{Latex[length=2mm,width=2mm]}] (a) -- (d)node[midway,below,sloped,color=black]{d};
            \draw[-{Latex[length=2mm,width=2mm]}] (d) -- (e)node[midway,below,sloped,color=black]{e};
            \draw[-{Latex[length=2mm,width=2mm]}] (e) -- (f)node[midway,below,sloped,color=black]{f};
            \draw[-{Latex[length=2mm,width=2mm]}] (f) -- (g)node[midway,below,sloped,color=black]{g};
            \draw[-{Latex[length=2mm,width=2mm]}] (g) -- (h)node[midway,below,sloped,color=black]{h};
            \draw[-{Latex[length=2mm,width=2mm]}] (b) -- (h)node[midway,below,sloped,color=black]{i};
        \end{tikzpicture}
        \begin{tikzpicture}
            \filldraw (0,0) coordinate(a) circle (3pt);
            \filldraw (-1,1) coordinate(b) circle (3pt);
            \filldraw (0.3,0.9) coordinate(c) circle (3pt);
            \filldraw (0,-1.3) coordinate(d) circle (3pt);
            \filldraw (-1,-2) coordinate(e) circle (3pt);
            \filldraw (-2,-1.5) coordinate(f) circle (3pt);
            \filldraw (-3,-0.5) coordinate(g) circle (3pt);
            \filldraw (-2,0.5) coordinate(h) circle (3pt);

            \draw [-{Latex[length=2mm,width=2mm]},color=blue] (a) -- (b);
            \draw [-{Latex[length=2mm,width=2mm]}](a) -- (c);
            \draw [-{Latex[length=2mm,width=2mm]}](b) -- (c);

            \filldraw [opacity=0.3] (a) -- (b) -- (c);

            \draw[-{Latex[length=2mm,width=2mm]},color=blue] (a) -- (d);
            \draw[-{Latex[length=2mm,width=2mm]},color=blue] (d) -- (e);
            \draw[-{Latex[length=2mm,width=2mm]},color=blue] (e) -- (f);
            \draw[-{Latex[length=2mm,width=2mm]},color=blue] (f) -- (g);
            \draw[-{Latex[length=2mm,width=2mm]},color=blue] (g) -- (h);
            \draw[-{Latex[length=2mm,width=2mm]},color=blue] (b) -- (h);
        \end{tikzpicture}
        \begin{tikzpicture}
            \filldraw (0,0) coordinate(a) circle (3pt);
            \filldraw (-1,1) coordinate(b) circle (3pt);
            \filldraw (0.3,0.9) coordinate(c) circle (3pt);
            \filldraw (0,-1.3) coordinate(d) circle (3pt);
            \filldraw (-1,-2) coordinate(e) circle (3pt);
            \filldraw (-2,-1.5) coordinate(f) circle (3pt);
            \filldraw (-3,-0.5) coordinate(g) circle (3pt);
            \filldraw (-2,0.5) coordinate(h) circle (3pt);

            \draw [-{Latex[length=2mm,width=2mm]}] (a) -- (b);
            \draw [-{Latex[length=2mm,width=2mm]},color=blue](a) -- (c);
            \draw [-{Latex[length=2mm,width=2mm]},color=blue](b) -- (c);

            \filldraw [opacity=0.3] (a) -- (b) -- (c);

            \draw[-{Latex[length=2mm,width=2mm]},color=blue] (a) -- (d);
            \draw[-{Latex[length=2mm,width=2mm]},color=blue] (d) -- (e);
            \draw[-{Latex[length=2mm,width=2mm]},color=blue] (e) -- (f);
            \draw[-{Latex[length=2mm,width=2mm]},color=blue] (f) -- (g);
            \draw[-{Latex[length=2mm,width=2mm]},color=blue] (g) -- (h);
            \draw[-{Latex[length=2mm,width=2mm]},color=blue] (b) -- (h);
        \end{tikzpicture}
        \caption{An example for generators, that die due to a relation.
        In red is the boundary of a $2$-cell, in blue are two generators that are identified with each other via the $2$-cell.}
        \label{fig4}
    \end{figure}\\
    An example is given in Fig.~\ref{fig4}.
    We are given two circuits in blue, and a relation in red.
    If we number the edges as in the first picture and select all circuit orientations counter clockwise we get the following matrix:
    \[A=\begin{Bmatrix}
            1 & 0 & -1\\
            0 & 1 & 1\\
            0 & -1 & -1\\
            -1 & -1 & 0\\
            -1 & -1 & 0\\
            -1 & -1 & 0\\
            -1 & -1 & 0\\
            -1 & -1 & 0\\
            1 & 1 & 0
    \end{Bmatrix}\]
    And thus get a non-empty kernel, $A(1,-1,1)^T=0$.
    This corresponds to the two $1$-boundaries $P_1=[a,-c,-d,\ldots,i]$ and $P_2=[b,-c,-d,\ldots,i]$ being identified via the $2$-cell $R_1=[-a,b,-c]$.
    And this again corresponds to $P_1-P_2=-R_1\in C_2(C_\varepsilon(X))$, meaning $P_1 = P_2$ in $H_1(C_\varepsilon(X))$.
    So we know that the two generators are identified with each other and we may remove the younger one out of the generator list.\\
    We now know when to add edges, faces, how to find all possible generators and how to find ''dead'' generators.
    Putting this together we are now able to calculate the first persistent homology.

    \subsubsection{Optimizations}\label{subsec:optimizations}

    Since this method is not that efficient ($\sim5$ seconds for $100$ nodes, $\sim20$ seconds for $200$ nodes) we optimised it using contractions on the graph and get almost linear runtime ($\sim10$ seconds for $1000$ nodes).
    The main idea here is to handle the effect of each relation as operation on the underlying graph instead of maintaining a list of relations.
    That removes the necessity of computing kernels of a growing matrix in each face step, but is not trivial to implement due to special cases in face contractions.\\
    Let us recap first.
    We have generated a list of actions, that are of exactly three different types:
    \begin{itemize}
        \item Edge actions: These add exactly one edge between two nodes.
        \item Face actions: These add a relation going along the boundary of a face, representing the face being contracted.
        \item Edge-face actions: These exist for degenerate faces and first add an edge of a face before executing the face action.
    \end{itemize}
    Since we are going to add and remove edges, we first have to make sure, that we are sorting the actions in a way, that edges are first added and then removed.
    Logically this should be an implication by the action generation using the Voronoi diagram, but in reality there are sometimes numerical problems, that destroy this order.
    To do this, we compute a dependency tree, where a face or edge-face action is depending on each edge or edge-face action, that adds an edge of the relation of the face action.
    Afterwards we sort the actions using this tree order.\\
    Note that since we are now going to contract and remove edges and nodes, we have to allow multi-edges and loops inside the graph.
    Now we can start to process each action one by one.\\
    Edge actions are the same as before: We add the edge to the graph, independent from whether it is going to be a loop or normal edge.
    We also have to search for new circuit in the graph and eventually add a new cycle.
    Due to the way, we are searching for new circuits, we don't even have to change the algorithm when allowing newly added loops.\\
    Edge-face actions at first also add an edge the same way edge actions do, but we omit searching for circuits, since the newly created cycle would die the same time it is born.
    Then we add the face relation just like face actions do.\\
    This leaves us with the evaluation of face actions.
    We are now starting to modify edges and nodes inside the graph, which means that all future actions and all existing cycles have to be updated in the same way as well.
    Otherwise the modified graph would not be consistent with existing cycles and upcoming actions.
    To simplify this, we introduce circuits on the graph, which are defined by a list of oriented edges.
    Boundaries and faces can both be represented by circuits, so that we can apply the following operations simply to the graph and circuits.
    Homology is commutative but since we are representing boundaries and faces as oriented paths, we cannot use the commutativity and have to be more careful about modifying these.
    The lack of commutativity will later be handled by eliminating linear combinations of cycles.\\
    Let us now discuss how we replace nodes and replace and remove edges.
    Replacing nodes can for example be done by maintaining a node mapping table, but we decided to do that by having each graph node be an optional pointer to a target node.
    If for example we want to replace node $1$ with node $0$ using the elder rule, we have to set node $1$ to point to node $0$.\\
    Now we have a look at the more complicated replacement and removal of edges.
    Since we are replacing edges no matter the orientation, we have to replace all occurrences of that edge with the desired orientation and possibly inverse order (see Fig.\ \ref{fig5} \texttt{replace()}).
    Analogously we remove all occurrences of a single edge no matter the orientation when removing an edge from a circuit (see Fig.\ \ref{fig5} \texttt{remove()}).
    After both of those operations we try to reduce the circuit as far as possible by successively removing pairs of edges and their inverses (see Fig.\ \ref{fig5} \texttt{revalidate()}).\\
    \input{snippet2.tex}
    Now we have all the tools we need to actually evaluate face actions (see Fig.\ \ref{fig6}).\\
    Case 1 actually never occurs, since that would mean that the relation is a linear combination of other relations.\\
    Case 2.1 removes exactly one loop and case 2.2 occurs at the very start of the algorithm, where nothing has yet been contracted (see Fig.\ \ref{contractions} top left, bottom left).\\
    Case 3 first searches for a loop, that only occurs once (which is always possible, since otherwise all edges would have been gone through twice, which is impossible in a planar graph).
    Then it solves the relation for that loop, so that it can be replaced by the resulting sequence of other loops.
    For example in Fig.\ \ref{contractions} top right having the relation $[a, b, b, -c]$ we can find $a$ to be a single edge and replace it with $[c, -b, -b]$.
    That way we get rid of every occurrence of $a$ using the relation and delete it afterwards.\\
    Case 4 is the last case, where some $k$ loops as well as non-loops occur in the relation.
    Here we search for a single non-loop and replace it using the relation, just like as in case 3.
    %TODO: correct the following sentence!!!!!!
    Then we additionally contract all non-loops of the relation. We can do this, since the original boundary of the face was homologous to a $k+1$-bouquet.
    Gluing a face onto a $k+1$-bouquet results in a $k$-bouquet, where one of the loops gets identified with all other.
    So we pick one of the non-loops that forms (together with all other non-loops) part of the loop to be identified.
    We identify all other non-loops with $0$ via homotopy, and contract all the vertices to a single vertex.
    The selected non-loop gets mapped to all the other loops in the bouquet respecting the orientation and then gets deleted as well.
    In the example in Fig.\ \ref{contractions} bottom right we find edge $b$ to be occurring only once.
    We merge the two nodes, delete both edges and add the mappings $b$ to $[-c,-a]$ and $c$ to $0$.
    This way we eliminate all non-loops, that are part of the given relation each time and drastically reduce the size of the graph over time.
    \input{snippet3.tex}
    \input{contractions.tex}\\
    Afterwards we kill empty cycles and linear combinations of cycles.
    The elimination of linear combinations is still done by computing the null space of the edge matrix of all living cycles.
    However this matrix grows much slower and sometimes even shrinks in size, compared to the other method.
    This last step is also the part, that respects the commutativity of homology.

    \section{Modified Wasserstein distance}\label{sec:distance-measures}

    First of all we want to extend the Wasserstein distance to differently sized sets.
    A first idea was to minimize $\varphi:X\rightarrow Y$ for $|X|<|Y|$ via injections $\varphi:X\rightarrow Y$, and to introduce an error term for every point in $Y$ that is not hit.\\
    Define $\gamma:\bR^2\rightarrow\bR$, with $(x,y)\mapsto y-x$.
    The motivation behind this definition is that this is exactly the vertical distance from a point $(x,y)$ to the diagonal.
    Then we define \[W_p'(X,Y):=\min_{\varphi:X\rightarrow Y}\left(\sum_{x\in X}|||x-\varphi(x)||^p + \sum_{y\in Y\setminus \in(\varphi)}\gamma(y)^p\right)^\frac{1}{p}.\]
    This approach seemed promising at first, but the error term was too big.
    The problem is that $||x-\varphi(x)||$ is the $\ell_2$ distance of $x$ and $\varphi(x)$, whereas $\gamma(y)$ is the $\ell_1$ distance of $y$ and $\Delta$.
    Hence we define $\gamma(x,y)=\frac{y-x}{\sqrt{2}}$, to get the $\ell_2$ distance of $y$ and $\Delta$ instead.
    However we noticed that this distance is too restrictive.
    We also want to allow points from $X$ not to be mapped.
    So now we define the final version of our modified Wasserstein distance, where we apply the error term to any point from $X$ that is not mapped, as well as any point from $Y$ that is not hit.
    \[V_p(X,Y):=\min_{Z\subset{X}}\min_{\varphi:Z\rightarrow Y}\left(\sum_{z\in Z}||z-\varphi(z)||^p + \sum_{y\in (Y\setminus \im(\varphi))\cup X\setminus Z}\gamma(y)^p\right)^\frac{1}{p}.\]

    We call the Bottleneck distance $B(X,Y) := V_\infty(X,Y)$.
    Since we now have three different Wasserstein distances, we want to make clear, that the function $V_p(\_,\_)$ will be the distance in question from now on.\\
    In Figure\ \ref{distances} an example of all the different distances, a single point from the set $X$ has to consider is shown.
    We want to find a mapping the reduces the sum of the selected lengths, or the maximum such length respectively.
    \begin{figure}
        \centering
        \begin{tikzpicture}
            % Achsen zeichnen
            \draw[->,thick] (0,0) -- (5,0) node[right] {$x$};
            \draw[color=blue] (0,0) -- (5,5);
            \draw[->,thick] (0,0) -- (0,5) node[above] {$y$};
            %Punkte einzeichnen:
            \filldraw[color=green] (2,3) coordinate(a) circle (3pt);
            \filldraw[color=green] (1,1.1) coordinate(b) circle (3pt);
            \filldraw[color=green] (3.1,4) coordinate(c) circle (3pt);

            \filldraw[color=blue] (1,1.5) coordinate(d) circle (3pt);
            \filldraw[color=blue] (2,2.5) coordinate(e) circle (3pt);
            \filldraw[color=blue] (2.8,3.1) coordinate(f) circle (3pt);
            \filldraw[color=blue] (3.2,4.3) coordinate(g) circle (3pt);

            \draw[red] (2.5,2.5) -- (a);

            \draw[red] (d) -- (a);
            \draw[red] (e) -- (a);
            \draw[red] (f) -- (a);
            \draw[red] (g) -- (a);

        \end{tikzpicture}
        \caption{\textit{The first homology of two different persistence Diagrams in green and blue.
        Red are all the different distances, a single point of the green diagram has to consider in the mapping problem.}}
        \label{distances}
    \end{figure}

    \subsection{Efficient Calculation}\label{subsec:efficient-calculation}

    We quickly noticed that the whole problem can be modelled quiet easily via a min-cost-flow problem.
    This reduces the computations required from basically checking exponentially many mappings to finding a min-cost-flow, which can be done in polynomial time.\\
    So for $V_p(X,Y)$ we define the following graph.
    $V := X\cup Y\cup {s,t,h,h'}$ and $E := \big((X\cup h)\times (Y\cup h')\big) \cup \big({s}\times (X\cup h)\big) \cup \big((Y\cup h')\times t\big)$.
    \begin{figure}
        \centering
        \begin{tikzpicture}[scale = .95]
            \definecolor{mycolor}{rgb}{0, 0.500, 0.06};
            \definecolor{red}{rgb}{1,0,0};
            \definecolor{blue}{rgb}{0,0,1};
            \filldraw (0,0) coordinate(s) circle (3pt);
            \node at (s) [above = 1mm of s] {$s$};
            \node at (s) [left,blue] {$|X|+|Y|$};

            \filldraw (3,3) coordinate(x1) circle (3pt);
            \node at (x1) [above = 1mm of x1] {$x_1$};
            \filldraw (3,1) coordinate(x2) circle (3pt);
            \node at (x2) [above = 1mm of x2] {$x_2$};
            \filldraw (3,-1) coordinate(x3) circle (3pt);
            \node at (x3) [above = 1mm of x3] {$x_n$};
            \filldraw (3,-3) coordinate(h) circle (3pt);
            \node at (h) [above = 1mm of h] {$h$};



            \filldraw (6,4) coordinate(y1) circle (3pt);
            \node at (y1) [above = 1mm of y1] {$y_1$};
            \filldraw (6,2) coordinate(y2) circle (3pt);
            \node at (y2) [above = 1mm of y2] {$y_2$};
            \filldraw (6,0) coordinate(y3) circle (3pt);
            \node at (y3) [above = 1mm of y3] {$y_3$};
            \filldraw (6,-2) coordinate(y4) circle (3pt);
            \node at (y4) [above = 1mm of y4] {$y_m$};
            \filldraw (6,-4) coordinate(hs) circle (3pt);
            \node at (hs) [above = 1mm of hs] {$h'$};

            \filldraw (9,0) coordinate(t) circle (3pt);
            \node at (t) [above = 1mm of t] {$t$};
            \node at (t) [right,blue] {$-|X|-|Y|$};

            \draw [-{Latex[length=2mm,width=2mm]}] (s) -- (x1) node [midway,above, sloped] {$\textcolor{mycolor}{0},\textcolor{red}{1}$};
            \draw [-{Latex[length=2mm,width=2mm]}] (s) -- (x2) node [midway,above, sloped] {$\textcolor{mycolor}{0},\textcolor{red}{1}$};
            \draw [-{Latex[length=2mm,width=2mm]}] (s) -- (x3) node [midway,above, sloped] {$\textcolor{mycolor}{0},\textcolor{red}{1}$};
            \draw [-{Latex[length=2mm,width=2mm]}] (s) -- (h) node [midway,above, sloped] {$\textcolor{mycolor}{0},\textcolor{red}{|Y|}$};


            \draw [-{Latex[length=2mm,width=2mm]}] (x1) -- (y1) node [midway,above, sloped] {$\textcolor{mycolor}{||x_1-y_1||},\textcolor{red}{1}$};
            \draw [-{Latex[length=2mm,width=2mm]}] (x2) -- (y1) node [midway,near start,sloped,above] {$\ldots$};
            \draw [-{Latex[length=2mm,width=2mm]}] (x1) -- (y2) node [midway,above, sloped,fill=white,fill opacity = 0.8,color=white] {$x_1-y_2$}node [midway,above, sloped] {$\textcolor{mycolor}{||x_1-y_2||},\textcolor{red}{1}$};
            \draw [-{Latex[length=2mm,width=2mm]}] (x2) -- (y2)node [midway,sloped,above] {$\ldots$};
            \draw [-{Latex[length=2mm,width=2mm]}] (x2) -- (y3)node [midway,above, sloped] {$\textcolor{mycolor}{||x_2-y_3||},\textcolor{red}{1}$};

            \node at (4.5,0) {$\vdots$};

            \draw [-{Latex[length=2mm,width=2mm]}] (x3) -- (y4) node [midway,above, sloped] {$\textcolor{mycolor}{||x_n-y_m||},\textcolor{red}{1}$};
            \draw [-{Latex[length=2mm,width=2mm]}] (x3) -- (hs) node [midway,near start,below, sloped] {$\textcolor{mycolor}{\gamma(x_n)},\textcolor{red}{1}$};
            \draw [-{Latex[length=2mm,width=2mm]}] (h) -- (hs) node [midway,below, sloped] {$\textcolor{mycolor}{0},\textcolor{red}{\min(|X|,|Y|)}$};
            \draw [-{Latex[length=2mm,width=2mm]}] (h) -- (y4)node [midway,below, sloped,fill=white,fill opacity = 0.8, color=white] {$\gamma(y_m),1$}  node [midway,below, sloped] {$\textcolor{mycolor}{\gamma(y_m)},\textcolor{red}{1}$};



            \draw [-{Latex[length=2mm,width=2mm]}] (y1) -- (t) node [midway,above, sloped] {$\textcolor{mycolor}{0},\textcolor{red}{1}$};
            \draw [-{Latex[length=2mm,width=2mm]}] (y2) -- (t) node [midway,above, sloped] {$\textcolor{mycolor}{0},\textcolor{red}{1}$};
            \draw [-{Latex[length=2mm,width=2mm]}] (y3) -- (t) node [midway,above, sloped] {$\textcolor{mycolor}{0},\textcolor{red}{1}$};
            \draw [-{Latex[length=2mm,width=2mm]}] (y4) -- (t) node [midway,above, sloped] {$\textcolor{mycolor}{0},\textcolor{red}{1}$};
            \draw [-{Latex[length=2mm,width=2mm]}] (hs) -- (t) node [midway,above, sloped] {$\textcolor{mycolor}{0},\textcolor{red}{|X|}$};

            %\draw [-{Latex[length=2mm,width=2mm]},color=red] (a) -- (b) node[midway,below,sloped,color=black]{a};
            %\draw [-{Latex[length=2mm,width=2mm]},color=red](a) -- (c)node[midway,below,sloped,color=black]{b};
            %\draw [-{Latex[length=2mm,width=2mm]},color=red](b) -- (c)node[midway,above,sloped,color=black]{c};

            %\draw[-{Latex[length=2mm,width=2mm]}] (a) -- (d)node[midway,below,sloped,color=black]{d};
            %\draw[-{Latex[length=2mm,width=2mm]}] (d) -- (e)node[midway,below,sloped,color=black]{e};
            %\draw[-{Latex[length=2mm,width=2mm]}] (e) -- (f)node[midway,below,sloped,color=black]{f};
            %\draw[-{Latex[length=2mm,width=2mm]}] (f) -- (g)node[midway,below,sloped,color=black]{g};
            %\draw[-{Latex[length=2mm,width=2mm]}] (g) -- (h)node[midway,below,sloped,color=black]{h};
            %\draw[-{Latex[length=2mm,width=2mm]}] (b) -- (h)node[midway,below,sloped,color=black]{i};
        \end{tikzpicture}
        \caption{Structure of the constructed graph.
        Flow requirements are blue, capacities red and costs green.}
        \label{graph}
    \end{figure}

    Weights are selected as follows.
    For edges in $\big({s}\times (X\cup h)\big) \cup \big((Y\cup h')\times t\big) \cup \{(h,h')\}$ they are always 0.
    For edges of the form $(x,y)\in X\times Y$ the costs are exactly $||x-y||$, and for edges of the form $(x,h')\in X\times \{h'\}$ resp. $(h,y)\in \{h\}\times Y$ we select $\gamma(x)$ or $\gamma(y)$.
    As capacities we choose $|Y|,|Y|$ and $\min(|X|,|Y|)$ for $(s,h),(h',t)$ and $(h,h')$ respectively and $1$ for all other edges.
    And finally the flow requirements $b(s) = -b(t) = |X|+|Y|$, and $b(v)=0$ for all others.
    In Figure\ \ref{graph} one can see the structure of the constructed graph.\\
    In order to solve the Wasserstein distance via a min-cost flow instance, we must first prove that for every feasible integer flow there is a $Z\subset X$ and map $\varphi:Z\rightarrow Y$, where the cost of the flow is equal to the error term of $\varphi$ and vice versa.
    Since the graph only has integral values, the min-cost-flow is integral as well, which is why these are sufficient to consider.
    From this it follows that the cost of a min-cost-flow is equal to the Wasserstein distance.
    Note that this cost only applies to $p=1$.
    For $1<p<\infty$ exponentiate the cost of all edges by $p$ and return the $p$th root of the cost at the end.

    \begin{lemma}
        The cost of a min-cost-flow for the above graph $G=(V,E)$ is equal to the Wasserstein distance $V_p(X,Y)$.
    \end{lemma}
    \begin{proof}
        Let $f:E\rightarrow \bZ_{\geq0}$ be a feasible flow.
        For $Z$ choose all vertices $x$ from $X$, such that $f((x,y))=1$ for a $y\in Y$ and set $\varphi(x) = y$ for this $y$.
        In less mathy terms, $\varphi$ is given by the selected flow edges of $f$, between $X$ and $Y$.
        Since the cost of the edges of the form $(x,h')$ or $(h,y)$ selected by the flow is exactly $\gamma(x)$ and $\gamma(y)$, $V_p(X,Y)$ is a lower bound for the min-cost-flow value.\\
        For the other direction we consider for given $Z,\varphi$ the flow given by $f(x,y)=1$ iff $x\in Z$ and$ \varphi(x)=y$.
        For all $x\in X\setminus Z$ we set $f((x,h'))=1$ and for $y\in Y\setminus \im(\varphi)$ we set $f((h,y))=1$.
        Thus one receives a feasible flow, with the same costs.
    \end{proof}

    And as we know, the min-cost-flow problem can be calculated in polynomial time with an algorithm like Edmonds-Karp or Dinic's.\\
    To calculate the Bottleneck distance, we consider the subgraph given by all edges with weights smaller than a given value.
    Since the Bottleneck distance is given by the cheapest edge, so that with all cheaper edges a feasible flow is still possible, one can determine the Bottleneck distance with logarithmically many calls of a min-cost-flow algorithm with a procedure like binary search.
    This reduction follows from the fact, that the error term that is to be minimized in the Wasserstein distance is the same as the $p$-norm.
    The Bottleneck distance hence is the same as the $\infty$-norm, and is described by the maximum.
    Hence the Bottleneck distance reduces to finding the value 
    \begin{gather*}
    	\min_{\varphi:Z\subset X \rightarrow Y} \max\bigg(\max_{x\in Z}||x - \varphi(x)||,\max_{y\in Y\setminus\im\varphi\cup X\setminus Z}\gamma(y)\bigg)\\
    	= \min\bigg\{C\in\bR \bigg| (V,E_C) \text{ permits an |X|+|Y| flow}\bigg\},
    \end{gather*}\\
    where $E_C=\{e\in E | c(e) < C\}$.
	This leaves us with the following run time for both distances.\\
    Let $X$ and $Y$ again be arbitrary.
    Then the graph consists of $n=2+|X|+|Y|$ vertices and $m=3+2|X|+2|Y|+|X||Y|$ edges.
    Assuming a runtime of $O(n^2 m)$ for Dinic's algorithm, we have a runtime of $O(|X||Y|^3 + |X|^3|Y|)$ for the Wasserstein distance.
    For the Bottleneck distance we get a runtime of $O(\log(|X||Y|)(|X||Y|^3 + |X|^3|Y|))$.
    Note that Dinic's Algorithm is not necessarily the fastest for this type of problem, since the very easy structure of the graph opens the door to more specialized algorithms.

    \section{Feature Proposals}\label{sec:feature-proposals2}
    To combine all of this to actually calculate a distance of two images, we need to reduce an image to a point set.
    For this we looked at different types of feature detection algorithms and compared these.
    \subsection{Feature Detection}\label{subsec:feature-detection}
    To do this we first considered an image, converted it to grayscale and then tried out existing feature detection algorithms.
    We tested the Laplace operator, the Harris operator and Canny edge detection.\\
    The Laplace operator computes the 2nd spatial derivative and therefore may output many different gray values for one image, which is less usable for our approach.
    That is because we are trying to represent image structures with points, which is not possible to do in an accurate manner, if the feature detection outputs only a ''probability'' for an edge or corner.\\
    Next up is the harris operator, which highlights corners inside an image.
    One could think, that this is exactly what we need, but in fact we need to describe lines as series of points and not only start and end point.
    That rules out the Harris operator for our case as well.
    \input{snippet4.tex}\\
    Finally we tested the Canny operator, which only outputs either 0 or 1 for each pixel, given a threshold.
    Its used for edge detection and given the previous explanation exactly what we need.
    There might be some dynamic threshold computation left to do, so that the user doesn't have to choose that parameter on its own.
    \subsection{Feature Selection}\label{subsec:feature-selection}
    Now we have a feature detection, that outputs a bitmap with ones for all edges in the image.
    The next thing to do is to convert that bitmap into 2D points, that will be used to compute the persistent homology.
    The idea behind the used algorithm is inspired by Poisson-Disc sampling and works as follows:
    We sample the area above the threshold by only sampling points, that are at least twice a given radius $r$ away from all other samples (see fig.~\ref{fig8}).\\
    The result is a set of points, that resemble the original area, and we could put discs of radius $r$ around each sampled point, without any discs intersecting.
    That way we have control over the granularity of the sampling using only a radius parameter.
    The given space between each sample also ensures, that the numerical accuracy of the Voronoi algorithm does not have to be that exact.
    \section*{Conclusion}\addcontentsline{toc}{section}{Conclusion}
    In this work we have presented two different ways to compute the persistent homology of a given $2$-dimensional point set.
    We began with a very na\"{\i}ve way, where we simply built up a big matrix, and continuously solved it for its kernel.
    We then used information from the kernel to reduce the size of the matrix and gather information about the persisten homology.\\
    The second approach was much more involved, and made changes to the underlying graph, to keep the complexity of the problem small from the very beginning.
    For this we had to be careful, to respect the homology.\\
    We then used the calculated persistent homology, to compute their difference.
    For this we changed the Wasserstein and Bottleneck distances to also accept differently sized point sets and made this change in a way, that it respects the significance of the underlying data - namely the persistent homology.\\
    To compute this, we reduced the problem to a flow-instance, and showed, that the distances can be computed in polynomial time.
    Namely for $|X|=n$ and $|Y|=m$ we achieved a run time of $O(nm^3+n^3 m)$ and $O(\log(nm)(nm^3+n^3 m))$ respectively.\\
    To put all of this to use, we presented some already well-known methods, to reduce an input image to a set of points, that represent the shape of the object in the image well.
    We also presented a method, of how to reduce the number of these point sets to increase the speed of our method without loosing much of the accuracy.\\
    An important limitation however is, that this handcrafted approach really only works well with $2$-dimensional data.
    It would be interesting to see, if there is a similar approach to the contractions on the graph for higher dimensional input data/a Čech complex with higher non-trivial homologies.\\
    Another limitation is, that this distance is quite reliant on scale, since a scaled image produce scaled persistence diagrams.
    And since our Wasserstein distance version does not consider different scales, this produces big distances between scaled images.
    \newpage
    \section*{Notes on the Java Program}\addcontentsline{toc}{section}{Notes on the Java Program}
    The Java program is a maven project and therefore does not need any prerequisites but a java SDK of version 11+ and optionally a GNU plot installation.
    There are four different applications:
    \begin{itemize}
        \item DistanceApp: Allows the user to define two point sets and compute and visually display the Wasserstein and Bottleneck distances.
        \item FeatureApp: Allows the user to load images, compute feature sets using different selection algorithms and sample the result using disc sampling.
        \item HomologyApp: Allows the user to generate point sets and iteratively or completely compute and visualise the homology.
        \item MainApp: Allows the user to open two images and compute the Wasserstein and Bottleneck distance between them.
    \end{itemize}
    All applications can be executed from the source code.
    It is also possible to execute the package maven goal with any of the profiles \texttt{distance}, \texttt{feature}, \texttt{homology} or \texttt{main} active.
    Doing that generates a jar file inside the target folder, that can be executed using simply \texttt{java -jar [file]} with a java runtime.
    Each executable generated jar file ends with \texttt{jar-with-dependencies.jar}.
    You can find the executable jar files attached as well.\\\\
    Here is a quick usage for each of those applications:\\
    DistanceApp:\\
    You can add points by left- or right-clicking with the mouse.\\
    Keyboard shortcuts:
    \begin{itemize}
    	\itemsep0em 
        \item Space: Compute distances
        \item Delete: Delete all points
        \item W: Toggle rendering of Wasserstein distance
        \item B: Toggle rendering of Bottleneck distance
        \item I: Load red points from file
        \item O: Load blue points from file
        \item P: Set specific $p$ for the Wasserstein distance
    \end{itemize}
    FeatureApp:\\
    Keyboard shortcuts:
    \begin{itemize}
    	\itemsep0em 
        \item O: Open image from file
        \item L: Compute Laplace operator
        \item H: Compute Harris operator
        \item C: Compute Canny operator with the current threshold
        \item +: Increase threshold
        \item -: Decrease threshold
        \item Space: Sample the filtered image using disc sampling
        \item R: Reset to opened image
        \item Escape: Close the application
    \end{itemize}
    HomologyApp:\\
    You can add points using left- and remove them using right-clicks.
    Existing points can be dragged using the left mouse button.\\
    Keyboard shortcuts:
    \begin{itemize}
    	\itemsep0em 
        \item Ctrl+O: Open a saved point file
        \item Ctrl+S: Save current point set to a file
        \item Ctrl+Shift+O: Import sampling from an image file
        \item Ctrl+Shift.S: Export persistence diagram to a file
        \item Escape: Close the application
        \item Space: Execute the next action
        \item Enter: Execute all (remaining) actions
        \item Ctrl+R: Reset cycles and actions
        \item Delete: Remove all points
        \item Ctrl+Shift+R: Add $10$ random points
        \item Ctrl+C: Toggle display of cycles (top left)
        \item Ctrl+A: Toggle display of actions (top right)
        \item Ctrl+D: Toggle display of Delaunay edges
        \item Ctrl+E: Toggle display of Voronoi edges
        \item Ctrl+V: Toggle display of Voronoi vertices
        \item Ctrl+Scroll-wheel: Increase/decrease vertex size (visualisation of persistence diagram)
        \item Ctrl+P: Plot persistence diagram using GNU plot (you will be asked to locate the gnuplot.exe)
    \end{itemize}
    MainApp:\\
    You will be asked to open two image files and then the application computes and outputs the Wasserstein distance for $p=1$ and the Bottleneck distance.
    
    %TODO Konsistenz (Rechtschreibung)
    %TODO why the fuck white points in poisson disc sampling
    
    \input{caseanalysis}

    \newpage
    \addcontentsline{toc}{section}{Literatur}
    \bibliography{literatur}
\end{document}